{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1 - Leia o arquivo abalone.csv, converta a primeira coluna de dados \n",
    "categóricos para numéricos usando o one-hot encoding. \n",
    "A função get_dumies parece ser mais conveniente que o \n",
    "    one-hot-encoded do scikit learn. A última coluna será  transformada  em \n",
    "    um dado categórico. A classe de saída será 1 se a ultima coluna for \n",
    "    maior que 13 e 0 se menor ou igual a 13. Uma vez que vc criou o atributo \n",
    "    de saída remova a ultima coluna. Separe os primeiros 3133 dados como \n",
    "    treino e os restantes como teste.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preferi usar as funções do sklearn ao invés do get_dummies do pandas, \n",
    "percebi que dependendo do tipo de dados (DataFrame ou numpy array) pode \n",
    "ter alguma diferença de arredondamento nos resultados, \n",
    "diferenças do tipo 0.896  e 0.897*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Eu preferi usar o sklearn ao invés do get_dummies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, binarize\n",
    "\n",
    "# lê os dados do csv\n",
    "dataset= pd.read_csv(\n",
    "        '/home/mauricio/projects/MO444/lista 2/abalone.csv').values\n",
    "# Primeiro transformo a coluna categórica (M,F,I) em numérica (0,1,2) \n",
    "labelEncoder = LabelEncoder()\n",
    "# transforma a primeira coluna (M,F,I) em (0,1,2) \n",
    "dataset[:,0] = labelEncoder.fit_transform(dataset[:,0])\n",
    "# Agora eu aplico o One Hot Coding na primeira coluna\n",
    "oneHotEncoder = OneHotEncoder(categorical_features=[0])\n",
    "dataset = oneHotEncoder.fit_transform(dataset).toarray()\n",
    "# Separo a última coluna para poder binarizar\n",
    "target = dataset[:,10].reshape(-1,1)\n",
    "#Para valores > 13 transformo em 1, para valores <= 13 transformo em 0\n",
    "binarize(target,threshold=13, copy=False)\n",
    "#Substituo os valores transformados no dataset original\n",
    "dataset = np.delete(dataset,-1,1)\n",
    "# Separa os primeiros 3133 dados como treino e os restantes como teste.\n",
    "X_training = dataset[0:3133,:]\n",
    "Y_training = target[0:3133,:]\n",
    "X_test = dataset[3133:4176,:]\n",
    "Y_test = target[3133:4176,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Função comum aos exercícios a seguir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regressao Logistica C=1000000, random_state=1\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ex_number é apenas o numero do exercício a ser resolvido para efeito \n",
    "# de visualização do resultado na tela\n",
    "# reg é o valor de C para ajustar o nível de regularização\n",
    "def execute_logistic_regression(\n",
    "        ex_number, reg, X_training, X_test, Y_training, Y_test):\n",
    "    \n",
    "    # Cria o classificador com C = parâmetro reg e random_state = 1\n",
    "    classifier = LogisticRegression(C=reg, random_state=1)\n",
    "    # Treina o modelo\n",
    "    classifier.fit(X_training, np.ravel(Y_training))\n",
    "    # Calcula a acuracia do classificador com os dados de testes\n",
    "    score = classifier.score(X_test, np.ravel(Y_test))\n",
    "    #Imprime a acuracia com 3 casas decimais de precisao\n",
    "    print(\"A acurácia do exercício {} com C = {} é = {:.3f}\".format(\n",
    "           ex_number, reg, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**2 - Regressão logística com C = 1000000. Faca a regressão logística dos dados \n",
    " transformados, com um C alto (sem regularização). Imprima  a  acurácia  do \n",
    " classificador nos dados de  teste com 3 dígitos  significativos.  Rode  o \n",
    "LogisticrRgression com random_state=1 para garantir que de o mesmo resultado \n",
    "toda vez que vc rodar (isso seta o valor da semente  do  gerador aleatório e \n",
    " portanto  usará  sempre  o  mesmo  ponto inicial na otimização da regressão \n",
    "logística).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do exercício 2 com C = 1000000 é = 0.896\n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador com C = 1000000\n",
    "execute_logistic_regression(\n",
    "    2, 1000000, X_training, X_test, Y_training, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 - Regressão logística com regularização (C=1). Imprima com 3 dígitos a \n",
    "acurácia, e use random_state=1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do exercício 3 com C = 1 é = 0.892\n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador com C = 1\n",
    "execute_logistic_regression(\n",
    "    3, 1, X_training, X_test, Y_training, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4 - Regressão logística sem regularização  e  com estandardização dos dados. \n",
    "Use C=1000000 mas transforme os dados antes de aplicar a regressão logistica.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Percebemos que aplicar Standarização nesse caso não apresenta \n",
    "nenhuma diferença no resultado final*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do exercício 4 com C = 1000000 é = 0.896\n"
     ]
    }
   ],
   "source": [
    "# Standarizaçao\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "standard_scaler = StandardScaler()\n",
    "# Cria o modelo baseado nos dados de treinamento\n",
    "standard_model =  standard_scaler.fit(X_training)\n",
    "#transforma os dados de treinamento\n",
    "standard_X_training = standard_model.transform(X_training)\n",
    "#transforma os dados de teste\n",
    "standard_X_test = standard_model.transform(X_test)\n",
    "# Cria o classificador com C = 1000000\n",
    "execute_logistic_regression(\n",
    "        4, 1000000, standard_X_training, standard_X_test, \n",
    "        Y_training, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5 - Aplique um PCA nos dados, de forma que pelo menos 90% da variância dos dados \n",
    "seja preservada.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PCA 90% da variancia preservada\n",
    "from sklearn.decomposition import PCA\n",
    "# Cria um modelo para manter 90% da variância dos dados de treinamento\n",
    "pca = PCA(n_components=0.90)\n",
    "pca_model = pca.fit(X_training)\n",
    "# Agora com o mesmo modelo reduzimos a dimensao dos dados de treinamento\n",
    "# e de testes \n",
    "pca_X_training = pca_model.transform(X_training)\n",
    "pca_X_test = pca_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6 - Rode a regressão logística sem regularização nos dados do PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Nesse caso foram selecionadas poucas dimensões e o resultado ficou \n",
    "pior do que com todas as dimensões*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do exercício 6 com C = 1000000 é = 0.884\n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador com C = 1000000\n",
    "execute_logistic_regression(\n",
    "        6, 1000000, pca_X_training, pca_X_test, Y_training, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7 - Rode a regressão logística com regularização (C=1) nos dados do PCA** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Como no exercício anterior, foram selecionadas poucas dimensões \n",
    "e mesmo rodando com regularização o resultado ficou pior do que \n",
    "com todas as dimensões*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do exercício 7 com C = 1 é = 0.884\n"
     ]
    }
   ],
   "source": [
    "# Cria o classificador com C = 1\n",
    "execute_logistic_regression(\n",
    "        7, 1, pca_X_training, pca_X_test, Y_training, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8 - Leia o arquivo abalone-missing.csv com dados faltantes na 2 a penúltima coluna. \n",
    "Faça o preprocessamento descrito em 1.  e  impute  pela média os valores faltantes. \n",
    "Rode a regressão sem regularização, sem PCA e sem estandardização.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A acurácia do exercício 8 com C = 1 é = 0.888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "#Carrega a base com dados faltantes\n",
    "dataset_missing_values = pd.read_csv(\n",
    "    '/home/mauricio/projects/MO444/lista 2/abalone-missing.csv').values\n",
    "        \n",
    "# Primeiro transformo a coluna categorica (M,F,I) em numerica (0,1,2) \n",
    "labelEncoder = LabelEncoder()\n",
    "# transforma a primeira coluna (M,F,I) em (0,1,2) \n",
    "dataset_missing_values[:,0] = labelEncoder.fit_transform(\n",
    "        dataset_missing_values[:,0])\n",
    "        \n",
    "imputer = Imputer()\n",
    "# Crio o modelo para preecher os dados faltantes com a media usando apenas\n",
    "# os dados de treinamento \n",
    "imputer_model = imputer.fit(dataset_missing_values[0:3133,:])\n",
    "# Agora com o modelo criado para os dados de treinamento faço a \n",
    "# transformaçao no conjunto todo (dados de treino e dados de testes)\n",
    "dataset_missing_values = imputer_model.transform(dataset_missing_values)\n",
    "\n",
    "# Agora eu aplico o One Hot Coding na primeira coluna\n",
    "oneHotEncoder = OneHotEncoder(categorical_features=[0])\n",
    "dataset_missing_values = oneHotEncoder.fit_transform(\n",
    "        dataset_missing_values).toarray()\n",
    "\n",
    "# Separo a ultima coluna para poder binarizar\n",
    "target_missing = dataset_missing_values[:,10].reshape(-1,1)\n",
    "\n",
    "#Para valores > 13 transformo em 1, para valores <= 13 transformo em 0\n",
    "binarize(target_missing,threshold=13, copy=False)\n",
    "\n",
    "#Substituo os valores transformados no dataset original\n",
    "dataset_missing_values = np.delete(dataset_missing_values,-1,1)\n",
    "\n",
    "# Separa os primeiros 3133 dados como treino e os restantes como teste.\n",
    "X_train_miss = dataset_missing_values[0:3133,:]\n",
    "Y_train_miss = target_missing[0:3133,:]\n",
    "X_test_miss = dataset_missing_values[3133:4176,:]\n",
    "Y_test_miss = target_missing[3133:4176,:]\n",
    "\n",
    "execute_logistic_regression(\n",
    "        8, 1, X_train_miss, X_test_miss, Y_train_miss, Y_test_miss)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Colocando os dados faltantes deu resultado razoável, mas naturalmente não \n",
    "teve o mesmo resultado com todos os dados preenchidos*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
