{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados ex6-train.csv representam um problema de regressão. A última coluna \n",
    "coluna é o valor a ser aproximado.\n",
    "\n",
    "Use várias técnicas para fazer a regressão ( SVM regressão, gbm, rf, redes neurais, \n",
    "knn, gaussian regression, e outras mesmo que não tenhamos visto em aula). A métrica \n",
    "séra MAE - erro absoluto médio (nao erro quadrado!).\n",
    "\n",
    "O relatório deve conter a sua exploracão de pelo menos 2 das téecnicas de regressao \n",
    "(mais o pre-processamento, se for o caso), os hiperparâmetros tentados e o erro (MAE). \n",
    "O relatório valerá 60% da nota.\n",
    "\n",
    "Rode o seu melhor regressor nestes dados, e submita também o resultado do valor predito, \n",
    "um por linha na mesma ordem dos dados. Note que é um resultado por linha.\n",
    "\n",
    "Eu avaliarei o MAE do seu regressor nos resultados corretos. 40% restante da nota sera \n",
    "competitiva: as submissões no topo 10% com menos MAE receberão o 10 nessa parte e as \n",
    "submissões nos últimos 10% (maiores MAE) receberão 0.\n",
    "\n",
    "Note que o dataset é grande (50.000 linhas e 77 atributos). Talvez não valha a pena fazer \n",
    "a exploração dos algoritimos e a busca de hiperparâmetros no dataset inteiro.\n",
    "\n",
    "ATENCAO: é preciso submeter 2 arquivos, o pdf com o relatório (60% da nota) e um csv com os \n",
    "valores computados para os dados em ex6-test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested cross validation para escolher os melhores parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import random\n",
    "\n",
    "# Escolhe os melhores parâmetros para os regressores\n",
    "def nested_cross_validation(param_grid, regressor, dataset, target):\n",
    "    # O Grid Search já é criado com valores de 3-fold e StratifiedKfold\n",
    "    # por default\n",
    "    \n",
    "    gridSearch = GridSearchCV(\n",
    "            estimator = regressor, param_grid = param_grid, cv = 3, \n",
    "            scoring='neg_mean_absolute_error', n_jobs=8)\n",
    "    gridSearch.fit(dataset, target)\n",
    "    # Faço a validaçao cruzada com 5-fold\n",
    "    cross_val_predict(gridSearch, X = dataset, y = target, cv = 5, \n",
    "                      n_jobs=8)\n",
    "    # Retorno os melhores parametros encontrados pelo Grid Search\n",
    "    return gridSearch.best_params_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lê o arquivo de entrada com 50000 linhas e separa os valores de entrada e de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '/home/mauricio/projects/MO444/lista 6/ex6-train.csv'\n",
    "# Arquivo completo\n",
    "dataset_full = pd.read_csv(file).values\n",
    "target_full = dataset_full[:,-1]\n",
    "X_train_full = np.delete(dataset_full,-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria um dataset com 20% dos dados, escolhidos aleatoriamente e separa os valores de Entrada e de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Conta as linhas\n",
    "num_lines = sum(1 for l in open(file))\n",
    "#  20% dos dados\n",
    "size = int(num_lines / 5)\n",
    "# Cria dataset com 20% dos dados\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - size)\n",
    "dataset_sample = pd.read_csv(file, skiprows=skip_idx).values\n",
    "target_sample = dataset_sample[:,-1]\n",
    "X_train_sample = np.delete(dataset_sample,-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria 2 datatsets com valores standardizados e com PCA (full e com 20% dos dados). O PCA foi feito com 98% dos dados porque foi o que conseguimos os melhores valores de erro (MAE) nos regressores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "standard_scaler = StandardScaler()\n",
    "X_train_scaler_full = standard_scaler.fit_transform(X_train_full)\n",
    "X_train_scaler_sample = standard_scaler.fit_transform(X_train_sample)\n",
    "# PCA para Reduzirmos dimensão dos dados para manter 98% da variância\n",
    "pca = PCA(n_components=0.98)\n",
    "X_train_pca_full = pca.fit_transform(X_train_scaler_full)\n",
    "X_train_pca_sample = pca.fit_transform(X_train_scaler_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear com Arquivo completo (50000 linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression()\n",
    "# Sem PCA\n",
    "linear_model = linear_regression.fit(X_train_full, target_full)\n",
    "linear_regression_mae_error = mean_absolute_error(\n",
    "    target_full, linear_model.predict(X_train_full))\n",
    "print(\"Linear Regression MAE[%0.3f]\" %linear_regression_mae_error)\n",
    "\n",
    "# Com PCA\n",
    "linear_model = linear_regression.fit(X_train_pca_full, target_full)\n",
    "linear_regression_mae_error = mean_absolute_error(\n",
    "    target_full, linear_model.predict(X_train_pca_full))\n",
    "print(\"Linear Regression PCA MAE[%0.3f]\" %linear_regression_mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression MAE[0.107] \n",
    "\n",
    "Linear Regression PCA MAE[0.107]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVR com amostragem (10000 linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVR - Nested Cross Validation\n",
    "param_grid_svr = [{'C': [2**(-5), 2**(0), 2**(5), 2**(10)], \n",
    "                    'gamma':[ 2**(-15),2**(-10),2**(-5),2**(0),2**(5)],\n",
    "                    'epsilon':[0.1, 1.5]}]\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "\n",
    "# Sem PCA\n",
    "svr_best_param = nested_cross_validation(param_grid_svr, svr_rbf, \n",
    "                                         X_train_sample, target_sample)\n",
    "print(\"SVR Best parameters\")\n",
    "print(svr_best_param)\n",
    "\n",
    "# Com PCA\n",
    "svr_best_param = nested_cross_validation(param_grid_svr, svr_rbf, \n",
    "                                         X_train_pca_sample, target_sample)\n",
    "print(\"SVR Best parameters PCA\")\n",
    "print(svr_best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR Best parameters\n",
    "{'C': 1024, 'epsilon': 0.1, 'gamma': 3.0517578125e-05}\n",
    "\n",
    "SVR Best parameters PCA\n",
    "{'C': 32, 'epsilon': 0.1, 'gamma': 3.0517578125e-05}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com a escolha dos parâmetros realizada, faço o treinamento e calculo o MAE no conjunto completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sem PCA\n",
    "svr_rbf = SVR(kernel='rbf', C=1024, gamma=3.0517578125e-05, epsilon=0.1)\n",
    "svr_rbf.fit(X_train_full, target_full)\n",
    "svr_mae_error = mean_absolute_error(target_full, \n",
    "                                    svr_rbf.predict(X_train_full))\n",
    "print(\"SVR MAE [%0.3f] \"%svr_mae_error)\n",
    "\n",
    "# Com PCA\n",
    "svr_rbf = SVR(kernel='rbf', C=32, gamma=3.0517578125e-05, epsilon=0.1)\n",
    "svr_rbf.fit(X_train_pca_full, target_full)\n",
    "svr_mae_error = mean_absolute_error(target_full, \n",
    "                                    svr_rbf.predict(X_train_pca_full))\n",
    "print(\"SVR MAE PCA [%0.3f] \"%svr_mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVR MAE [0.081] \n",
    "\n",
    "SVR MAE PCA [0.099]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KernelRidge com amostragem (10000 linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KernelRidge - Nested Cross Validation\n",
    "param_grid_ridge = [{'alpha': [2**(-5), 2**(0), 2**(5), 2**(10)], \n",
    "                    'gamma':[ 2**(-15),2**(-10),2**(-5),2**(0),2**(5)]}]\n",
    "kernel_ridge = KernelRidge(kernel='rbf')\n",
    "\n",
    "# Sem PCA\n",
    "ridge_best_param = nested_cross_validation(param_grid_ridge, kernel_ridge, \n",
    "                                           X_train_sample, target_sample)\n",
    "print(\"kernel Ridge Best parameters\")\n",
    "print(ridge_best_param)\n",
    "\n",
    "# Com PCA\n",
    "ridge_best_param = nested_cross_validation(param_grid_ridge, kernel_ridge, \n",
    "                                           X_train_pca_sample, \n",
    "                                           target_sample)\n",
    "print(\"kernel Ridge Best parameters PCA\")\n",
    "print(ridge_best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "kernel Ridge Best parameters\n",
    "{'alpha': 0.03125, 'gamma': 3.0517578125e-05}\n",
    "\n",
    "kernel Ridge Best parameters PCA\n",
    "{'alpha': 0.03125, 'gamma': 3.0517578125e-05}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Com a escolha dos parâmetros realizada, faço o treinamento e calculo o MAE. Para o kernel Ridge não foi possível fazer o treinamento no conjunto completo, por falta de memória, então foi feito com metade dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 50% dos dados\n",
    "size_half = int(num_lines / 2)\n",
    "skip_idx = random.sample(range(1, num_lines), num_lines - size_half)\n",
    "dataset_sample_half = pd.read_csv(file, skiprows=skip_idx).values\n",
    "target_sample_half = dataset_sample_half[:,-1]\n",
    "\n",
    "# Sem PCA\n",
    "X_train_sample_half = np.delete(dataset_sample_half,-1,1)\n",
    "\n",
    "# Com PCA\n",
    "X_train_scaler_sample_half = standard_scaler.fit_transform(\n",
    "    X_train_sample_half)\n",
    "X_train_pca_sample_half = pca.transform(X_train_scaler_sample_half)\n",
    "# Dataset full com PCA e mesmo nr de dimensões usados no treino\n",
    "X_train_full_pca_ridge =  pca.transform(X_train_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_ridge = KernelRidge(kernel='rbf', alpha=0.03125, \n",
    "                           gamma=3.0517578125e-05)\n",
    "# Sem PCA\n",
    "kernel_ridge.fit(X_train_sample_half, target_sample_half)\n",
    "ridge_mae_error = mean_absolute_error(target_sample_half, \n",
    "                                      kernel_ridge.predict(\n",
    "                                          X_train_sample_half))\n",
    "print(\"Kernel Ridge MAE [%0.3f] \"%ridge_mae_error)\n",
    "\n",
    "# Com PCA\n",
    "kernel_ridge.fit(X_train_pca_sample_half, target_sample_half)\n",
    "ridge_mae_error = mean_absolute_error(target_full, \n",
    "                                      kernel_ridge.predict(\n",
    "                                          X_train_full_pca_ridge))\n",
    "print(\"kernel Ridge MAE PCA [%0.3f] \"%ridge_mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Ridge MAE [0.086]\n",
    "\n",
    "Kernel Ridge MAE PCA [0.307]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest com amostragem (10000 linhas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Nested Cross Validation\n",
    "\n",
    "# Sem PCA\n",
    "param_grid_rf = [{'n_estimators': [ 100, 200, 400, 800], \n",
    "                 'max_features': [10, 30, 50, 77]}]\n",
    "random_forest = RandomForestRegressor()\n",
    "rf_best_param = nested_cross_validation(param_grid_rf, random_forest, \n",
    "                                        X_train_sample, target_sample)\n",
    "print(\"Random Forest Best parameters\")\n",
    "print(rf_best_param)\n",
    "\n",
    "# com PCA\n",
    "param_grid_rf = [{'n_estimators': [ 100, 200, 400, 800], \n",
    "                 'max_features': [8, 12, 17, 21]}]\n",
    "rf_best_param = nested_cross_validation(param_grid_rf, random_forest, \n",
    "                                        X_train_pca_sample, target_sample)\n",
    "print(\"Random Forest Best parameters PCA\")\n",
    "print(rf_best_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Best parameters\n",
    "{'max_features': 30, 'n_estimators': 400}\n",
    "\n",
    "Random Forest Best parameters PCA\n",
    "{'max_features': 17, 'n_estimators': 800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sem PCA \n",
    "random_forest = RandomForestRegressor(n_estimators=400, max_features=30)\n",
    "random_forest.fit(X_train_full, target_full)\n",
    "rf_mae_error = mean_absolute_error(target_full, \n",
    "                                   random_forest.predict(X_train_full))\n",
    "print(\"Random Forest MAE [%0.3f] \"%rf_mae_error)\n",
    "\n",
    "# Com PCA \n",
    "random_forest = RandomForestRegressor(n_estimators=800, max_features=17)\n",
    "random_forest.fit(X_train_pca_full, target_full)\n",
    "rf_mae_error = mean_absolute_error(target_full, \n",
    "                                   random_forest.predict(X_train_pca_full))\n",
    "print(\"Random Forest MAE PCA [%0.3f] \"%rf_mae_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Random Forest MAE [0.030]\n",
    "\n",
    "Random Forest MAE PCA [0.034]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões:\n",
    "- Foram feitos testes (não colocados todos aqui) usando separadamente \n",
    "a standardização e o PCA, mas os resultados não foram os melhores\n",
    "- Colocamos os resultados com os dados sem processamento e com \n",
    "stardardização+PCA para efeitos de comparação\n",
    "- O melhor resultado (com menor MAE) foi o Random Forest (MAE = 0.030)\n",
    "- Portanto é ele que iremos utilizar para gerar as predições no arquivo de \n",
    "testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fileTest = '/home/mauricio/projects/MO444/lista 6/ex6-test.csv'\n",
    "# Test dataset\n",
    "dataset_test = pd.read_csv(fileTest).values\n",
    "random_forest = RandomForestRegressor(n_estimators=400, max_features=30)\n",
    "random_forest.fit(X_train_full, target_full)\n",
    "y_prediction = random_forest.predict(dataset_test)\n",
    "pd.DataFrame(y_prediction).to_csv('prediction.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arquivo gerado prediction.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
