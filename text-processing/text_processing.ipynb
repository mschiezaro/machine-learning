{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O arquivo ex5-files.zip gera um diretório de diretórios (com as classes) e \n",
    "5000 textos divididos nos subdiretórios apropriados. Esse é o formato para \n",
    "a função sklearn.datasets.load_files\n",
    "\n",
    "O arquivo category.tab contém a classe de cada documento.\n",
    "\n",
    "Os textos sao parte de um data set de mineração de documentos com textos de \n",
    "tamanho médio sobre tecnlogia. As classes sao as classes originais dos textos.\n",
    "\n",
    "<b>Parte 1 - processamento de texto</b>\n",
    "\n",
    "Faça as tarefas usuais de processamento de textos:\n",
    "\n",
    "- conversão de caracteres maiúsculos para minúsculos\n",
    "- remoção de pontuação\n",
    "- remoção de stop words\n",
    "- steming dos termos\n",
    "- remoção dos termos que aparecem em um só documento ou que aparecem em todos.\n",
    "\n",
    "Converta os textos processados acima em um bag of words no formato binário (0/1 \n",
    "se o termo aparece ou não aparece no documento) e no formato de term frequency.\n",
    "\n",
    "Em Python, o sklearn tem funçẽes para gerar as diferentes formas da matriz \n",
    "termo-documento. \n",
    "\n",
    "O preprocessamento acima deve ser feito para todos os textos em conjunto. Não é \n",
    "preciso fazer a separação de fit no conjunto de treino e transform no conjunto \n",
    "de teste.\n",
    "\n",
    "Divida o conjunto em 1000 documentos de teste e 4000 de treino aleatoriamente \n",
    "(pode ser estratificado ou nao).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Carrega os dados \n",
    "dataset = load_files(\n",
    "        container_path= \"/home/mauricio/projects/MO444/lista 5/filesk\", \n",
    "        encoding='utf-8', random_state=1)\n",
    "# Conjunto de dados\n",
    "X = dataset.data\n",
    "# Label\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As classes CountVectorizer e TfidfVectorizer podem realizar todos os \n",
    "preprocessamentos pedidos no exercício, menos o steming dos termos. Portanto foi \n",
    "criado uma classe Tokenizer, para substituir o processo de tokenização padrão e \n",
    "usar a parte de steming no nltk <b>SnowballStemmer</b>.\n",
    "A Classe CountVectorizer criará um Bag of words binário e a TfidfVectorizer \n",
    "criará um Bag of words com term-frequency.\n",
    "\n",
    "Por default as classes CountVectorizer e TfidfVectorizer já fazem:\n",
    "- remoção de pontuação (e considerar apenas tokens de pelo menos 2 letras\n",
    "- conversão de caracteres maiúsculos para minúsculos \n",
    "(parâmetro <b>lowercase</b> pr default = <b>True</b>)\n",
    "\n",
    "E configuramos os que não são default:\n",
    "- remoção de stop words <b>stop_words = 'english</b>\n",
    "- steming dos termos <b>tokenizer=Tokenizer()</b>\n",
    "- remoção dos termos que aparecem em um só documento ou que aparecem em todos.\n",
    "<b>min_df = 2 e  max_df=0.99999</b> . \n",
    "\n",
    "O problemas desses parâmetros é que o valor\n",
    "não da condição não é um intervalo fechado, então para remover os termos que só \n",
    "aparecem 1 vez temos que configurar o <b>min_df</b> para q todos os valores \n",
    "menores que <b>min_df</b> sejam removidos ( e não menor ou igual).\n",
    "\n",
    "Para remover os termos que aparecem em todos os documentos temos que configurar \n",
    "o <b>max_df</b> para que todos os valores maiores que <b>max_df</b> sejam \n",
    "removidos (e não maior ou igual)\n",
    "\n",
    "A Classe CounterVectorizer foi configurada também para binarizar e não contar as \n",
    "ocorrências das palavras (<b>binary=True</b>)                              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Essa classe substituirá a parte de tokenização padrão do CountVectorizer e \n",
    "# TfidfVectorizer, porque precisamos usar o stem do nltk\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = CountVectorizer()\n",
    "        self.stemmer = SnowballStemmer(\"english\")\n",
    "    def __call__(self, doc):\n",
    "        tokens = self.tokenizer.build_tokenizer()(doc)\n",
    "        return [self.stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# Bag of words no formato binário\n",
    "binaryVectorizer = CountVectorizer(tokenizer=Tokenizer(),\n",
    "                                    min_df=2, \n",
    "                                    max_df=0.99999, \n",
    "                                    binary=True,\n",
    "                                    stop_words = 'english', \n",
    "                                    strip_accents = 'unicode')\n",
    "\n",
    "# Bag of words no formato de term frequency.\n",
    "tfidVectorizer = TfidfVectorizer(tokenizer=Tokenizer(), \n",
    "                                 min_df=2, \n",
    "                                 max_df=0.99999, \n",
    "                                 stop_words = 'english', \n",
    "                                 strip_accents = 'unicode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crio os conjuntos de treino e testes para o binário e para o Term-frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Binariza \n",
    "X_binary = binaryVectorizer.fit_transform(X)\n",
    "# Cria conjunto de teste e treino\n",
    "split_binary = train_test_split(X_binary, y, train_size=4000, \n",
    "                                test_size=1000, random_state=1)\n",
    "X_train_binary,X_test_binary,y_train_binary,y_test_binary = split_binary\n",
    "\n",
    "# Transforma em Term-frequency\n",
    "X_tfi = tfidVectorizer.fit_transform(X)\n",
    "# Cria conjunto de teste e treino\n",
    "split_tfi = train_test_split(X_tfi, y, train_size=4000, \n",
    "                                test_size=1000, random_state=1)\n",
    "X_train_tfi, X_test_tfi, y_train_tfi, y_test_tfi = split_tfi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parte 2 - naive bayes</b>\n",
    "\n",
    "Rode o naive bayes (BernoulliNB) na matriz binária. Qual a acurácia?\n",
    "\n",
    "Rode o naive Bayes (MultinomialNB) na matriz de term-frequency. Qual a acurácia\n",
    "(compare com a anterior)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bBernoulli_classifier = BernoulliNB()\n",
    "bBernoulli_classifier.fit(X_train_binary, y_train_binary)\n",
    "print(\"score BernoulliNB = %s\" % bBernoulli_classifier.score(\n",
    "        X = X_test_binary, y = y_test_binary))\n",
    "\n",
    "multinomialNB_classifier = MultinomialNB()\n",
    "multinomialNB_classifier.fit(X_train_tfi, y_train_tfi)\n",
    "print(\"score MultinomialNB = %s\" % multinomialNB_classifier.score(\n",
    "        X=X_test_tfi, y = y_test_tfi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>score BernoulliNB = 0.756</b></p>\n",
    "<b>score MultinomialNB = 0.602</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A acurácia do BernoulliNB com a matriz binária apresentou melhores resultados do \n",
    "que MultinomialNB com Term-frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Parte 3 -PCA e outros classificadores</b>\n",
    "\n",
    "Rode o PCA e reduza o número de dimensões da matriz de term-frequency para 99% \n",
    "da variância original. Você não consiguirá usar o PCA tradicional do Sklearn. \n",
    "Voce terá que usar o TuncatedSVD que é menos conveniente.\n",
    "\n",
    "Rode SVM com RBF (modo one vs all), gradient boosting e random forest na matriz \n",
    "com o número de dimensões reduzidas. Não se esqueça de fazer a busca de \n",
    "hiperparâmetros. Quais as acurácias?\n",
    "\n",
    "Qual o melhor classificador dos testados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = TruncatedSVD(n_components=3035, n_iter=10, random_state=1)\n",
    "pca.fit(X_train_tfi)    \n",
    "print(pca.explained_variance_ratio_.sum())\n",
    "\n",
    "X_train_tfi_pca = pca.transform(X_train_tfi)\n",
    "X_test_tfi_pca = pca.transform(X_test_tfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a variância de 99% do original foi usado o <b>n_components = 3035</b> e \n",
    "<b>n_iter = 10</b><p>\n",
    "\n",
    "<b>0.990019468958</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como estamos usando o OneVsRestClassifier e o SVC está sendo passado como \n",
    "parâmetro e na verdade queremos estimar os parâmetros do SVC temos que \n",
    "passar para o Grid Search os parâmetros a serem encontrados com o prefixo\n",
    "<b>estimator__</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# estimator__ como prefixo do parâmetro serve para entender que ele não é \n",
    "# do OneVsRestClassifier e sim do SVC\n",
    "p_svm_grid = [{'estimator__C': [2**(-5), 2**(0), 2**(5), 2**(10)],\n",
    "      'estimator__gamma': [2**(-15), 2**(-10), 2**(-5), 2**(0), 2**(5)]}]\n",
    "\n",
    "grid_svm = GridSearchCV(\n",
    "        estimator=OneVsRestClassifier(SVC(random_state=1)), \n",
    "        param_grid=p_svm_grid,\n",
    "        n_jobs = 8)\n",
    "grid_svm.fit(X_train_tfi_pca, y_train_tfi)\n",
    "\n",
    "ovr_svm = OneVsRestClassifier(\n",
    "        SVC(C = grid_svm.best_params_.get('estimator__C'),\n",
    "            gamma = grid_svm.best_params_.get('estimator__gamma')),\n",
    "        n_jobs = 8)\n",
    "ovr_svm.fit(X_train_tfi_pca, y_train_tfi)\n",
    "\n",
    "print(\"score tf-idf SVM = %s\" % ovr_svm.score(\n",
    "        X = X_test_tfi_pca, y= y_test_tfi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Best C = 1</b>\n",
    "\n",
    "<b>Best Gamma = 1</b>\n",
    "\n",
    "<b>score tf-idf SVM = 0.854</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_gb_grid = [{'n_estimators': [30, 70, 100],\n",
    "           'learning_rate': [0.1, 0.05]}]\n",
    "    \n",
    "grid_gb = GridSearchCV(\n",
    "       estimator=GradientBoostingClassifier(random_state=1, max_depth = 5), \n",
    "       param_grid=p_gb_grid,\n",
    "       n_jobs = 8)\n",
    "grid_gb.fit(X_train_tfi_pca, y_train_tfi)\n",
    "\n",
    "gb = GradientBoostingClassifier(\n",
    "        n_estimators = grid_gb.best_params_.get('n_estimators'),\n",
    "        learning_rate = grid_gb.best_params_.get('learning_rate'),\n",
    "        max_depth = 5)\n",
    "gb.fit(X_train_tfi_pca, y_train_tfi)\n",
    "\n",
    "print(\"score tf-idf GradientBoosting = %s\" % gb.score(\n",
    "        X = X_test_tfi_pca, y = y_test_tfi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Best n_estimators = 100</b>\n",
    "\n",
    "<b>Best learning_rate = 0.1</b>\n",
    "\n",
    "<b>sscore tf-idf GradientBoosting = 0.839</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid_rf = [{'n_estimators': [100, 200, 400, 800], \n",
    "                  'max_features': [1000, 1500, 2000, 3000]}]\n",
    "grid_rf = GridSearchCV(\n",
    "        estimator=RandomForestClassifier(random_state=1), \n",
    "        param_grid = param_grid_rf, \n",
    "        n_jobs = 8)\n",
    "grid_rf.fit(X_train_tfi_pca, y_train_tfi)\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "        n_estimators = grid_rf.best_params_.get('n_estimators'),\n",
    "        max_features = grid_rf.best_params_.get('max_features'),\n",
    "        random_state =  1,\n",
    "        n_jobs = 8)\n",
    "rf.fit(X_train_tfi_pca, y_train_tfi)\n",
    "\n",
    "print(\"score tf-idf Random Forest = %s\" % rf.score(\n",
    "        X = X_test_tfi_pca, y = y_test_tfi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Best n_estimators = 200</b>\n",
    "\n",
    "<b>Best max_features = 1500</b>\n",
    "\n",
    "<b>score tf-idf Random Forest = 0.823</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver nos resultados obtidos o SVM usando a técnica de One vs Rest \n",
    "obteve os melhores resultados. A busca por parâmetros e o treinamento para\n",
    "OneVsRestClassifier, GradientBoostingClassifier e RandomForestClassifier \n",
    "demoraram horas, mesmo em alguns casos configurando o algoritmo para usar\n",
    "8 cores de processamento (n_jobs = 8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
