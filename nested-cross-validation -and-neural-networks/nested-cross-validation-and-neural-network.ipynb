{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use os dados do arquivo abalone. Faça os pre-processamentos do exercício 3.\n",
    "Usando um 5-fold externo para calcular a acurácia, e um 3-fold interno para \n",
    "a escolha dos hiperparâmetros, determine qual algoritimo entre kNN, SVM com \n",
    "kernel RBF, redes neurais, Random Forest, e Gradient Boosting Machine tem a \n",
    "maior acurácia. Imprima a acurácia com 3 digitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67495143 -0.68813926  1.31710822 -1.44900723 -1.43989229 -1.18425209\n",
      "  -1.23034422 -1.17096695 -1.20532696 -1.21305408]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.0498915   0.12201495 -0.10824748\n",
      "  -0.30960118 -0.46361041 -0.35684354 -0.20727719]\n",
      " [-0.67495143 -0.68813926  1.31710822 -0.69955786 -0.4322102  -0.34735962\n",
      "  -0.63792816 -0.64833409 -0.60773918 -0.60240383]\n",
      " [-0.67495143  1.45319423 -0.75923905 -1.61555154 -1.5406605  -1.42336423\n",
      "  -1.27214983 -1.2160215  -1.28743825 -1.32081589]\n",
      " [-0.67495143  1.45319423 -0.75923905 -0.82446609 -1.08720356 -1.06469603\n",
      "  -0.97339267 -0.98399054 -0.94074611 -0.85384805]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.0498915   0.07163085  0.25042072\n",
      "  -0.10465173 -0.5514668  -0.35684354  0.65481729]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.17479973  0.17239906 -0.34735962\n",
      "  -0.12402506 -0.29465583 -0.28385572  0.15192884]\n",
      " [-0.67495143 -0.68813926  1.31710822 -0.40810533 -0.38182609 -0.34735962\n",
      "  -0.65118359 -0.64382864 -0.62142439 -0.53056262]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.21643581  0.32355137  0.25042072\n",
      "   0.13394613 -0.20229399 -0.27017051  0.58297608]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.00825543 -0.28105788  0.01130858\n",
      "  -0.45337169 -0.74520139 -0.30210268 -0.20727719]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, binarize\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "def pre_processing_data():\n",
    "    # lê os dados do csv\n",
    "    dataset= pd.read_csv(\n",
    "        '/home/mauricio/projects/MO444/lista 4/abalone.csv').values\n",
    "    # Primeiro transformo a coluna categorica (M,F,I) em numerica (0,1,2)\n",
    "    labelEncoder = LabelEncoder()\n",
    "    # transforma a primeira coluna (M,F,I) em (0,1,2)\n",
    "    dataset[:,0] = labelEncoder.fit_transform(dataset[:,0])\n",
    "    # Agora eu aplico o One Hot Coding na primeira coluna\n",
    "    oneHotEncoder = OneHotEncoder(categorical_features=[0])\n",
    "    dataset = oneHotEncoder.fit_transform(dataset).toarray()\n",
    "    # Separo a ultima coluna para poder binarizar\n",
    "    target = dataset[:,10].reshape(-1,1)\n",
    "    # Para valores > 13 transformo em 1, para valores <=13 transformo em 0\n",
    "    binarize(target,threshold=13, copy=False)\n",
    "    # Para funcionar com o StratifiedKFold\n",
    "    target.shape = (4176,)\n",
    "    #Substituo os valores transformados no dataset original\n",
    "    dataset = np.delete(dataset,-1,1)\n",
    "    # Standarização\n",
    "    standard_scaler = StandardScaler()\n",
    "    dataset = standard_scaler.fit_transform(dataset)\n",
    "    return dataset, target\n",
    "\n",
    "X, y = pre_processing_data()\n",
    "# Imprime somente os 10 primeiros dados\n",
    "print(X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Função comum para executar qualquer classificador usando Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# param_grid hiperparâmetros a serem testados\n",
    "# classifier Instancia do classificador\n",
    "# dataset dados\n",
    "# target Label de classficação \n",
    "def nested_cross_validation(param_grid, classifier, dataset, target):\n",
    "    # O Grid Search já é criado com valores de 3-fold e StratifiedKfold\n",
    "    # por default\n",
    "    gridSearch = GridSearchCV(\n",
    "            estimator = classifier, param_grid = param_grid, cv = 3)\n",
    "    gridSearch.fit(X, y)\n",
    "    # Faço a validaçao cruzada com 5-fold\n",
    "    nested_score = cross_val_score(\n",
    "        gridSearch, X = dataset, y = target, cv = 5)\n",
    "    # Retorno o resultado da classificação com a validação cruzada de \n",
    "    # 5-fold e também o Objeto para recuperarmos os melhores parâmetros \n",
    "    # encontrados pelo Grid Search\n",
    "    return nested_score, gridSearch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN\n",
    "1 - Para o kNN, faça um PCA que mantem 90% da variância. Busque os valores do k \n",
    "entre os valores 1, 5, 11, 15, 21, 25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média do KNN:  0.882\n"
     ]
    }
   ],
   "source": [
    "# PCA para Reduzirmos dimensão dos dados para manter 90% da variância\n",
    "pca = PCA(n_components=0.90)\n",
    "pca_X = pca.fit_transform(X)\n",
    "param_grid_knn = [{'n_neighbors': [ 1, 5, 11, 15, 21, 25]}]\n",
    "knn = KNeighborsClassifier()\n",
    "nested_knn, knn_grid = nested_cross_validation(\n",
    "    param_grid_knn, knn, pca_X, y)\n",
    "# Média da acurácia\n",
    "print(\"Acurácia média do KNN:  %0.3f\" %nested_knn.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "2 - Para o SVM RBF teste para C=$2^{-5}$, $2^{0}$, $2^{5}$, $2^{10}$ e gamma= $2^{-15}$, $2^{-10}$, $2^{-5}$, $2^{0}$, $2^{5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média do SVM:  0.892\n"
     ]
    }
   ],
   "source": [
    "param_grid_svm = [{'C': [2**(-5), 2**(0), 2**(5), 2**(10)], \n",
    "                 'gamma':[ 2**(-15), 2**(-10), 2**(-5), 2**(0), 2**(5)]}]\n",
    "# default ja é o RBF\n",
    "svm = SVC(random_state=1)\n",
    "nested_svm, svm_grid = nested_cross_validation(param_grid_svm, svm, X, y)\n",
    "# Média da acurácia\n",
    "print(\"Acurácia média do SVM:  %0.3f\" %nested_svm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rede Neural MLP\n",
    "3 - Para a rede neural, teste com 3, 7, 10, e 20 neurônios na camada escondida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n",
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média da MLP:  0.893\n"
     ]
    }
   ],
   "source": [
    "param_grid_mlp_net = [{'hidden_layer_sizes': [(3,), (7,), (10,), (20,)]}]\n",
    "mlp_net = MLPClassifier(random_state=1)\n",
    "nested_mlp, mlp_grid = nested_cross_validation(\n",
    "    param_grid_mlp_net, mlp_net, X, y)\n",
    "# Média da acurácia\n",
    "print(\"Acurácia média da MLP:  %0.3f\" %nested_mlp.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "4 - Para o RF, teste max_features = 2, 3, 5, 7 e n_estimators = 100, 200, 400 e 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média do Random Forest:  0.890\n"
     ]
    }
   ],
   "source": [
    "param_grid_rf = [{'n_estimators': [ 100, 200, 400, 800], \n",
    "                 'max_features': [2, 3, 5, 7]}]\n",
    "random_forest = RandomForestClassifier(random_state=1)\n",
    "nested_rf, rf_grid = nested_cross_validation(\n",
    "    param_grid_rf, random_forest, X, y)\n",
    "# Média da acurácia\n",
    "print(\"Acurácia média do Random Forest:  %0.3f\" %nested_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Machine\n",
    "5 - Para o GBM (ou XGB) teste para número de arvores = 30, 70, e 100, com learning \n",
    "rate de 0.1 e 0.05, e profundidade da árvore = 5.Você pode tanto usar a versão do \n",
    "SKlearn ou o XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média Gradient Boosting Machine: 0.888\n"
     ]
    }
   ],
   "source": [
    "param_grid_gb = [{'learning_rate':[ 0.1, 0.05], \n",
    "                  'n_estimators':[30, 70, 100]}]\n",
    "gb_machine = GradientBoostingClassifier(random_state=1, max_depth=5)\n",
    "nested_gb, gb_grid = nested_cross_validation(\n",
    "    param_grid_gb, gb_machine, X, y)\n",
    "# Média da acurácia\n",
    "print(\"Acurácia média Gradient Boosting Machine: %0.3f\" %nested_gb.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificador Final\n",
    "O melhor resultado ficou com as Redes Neurais, apesar de que a diferença ficou muito \n",
    "pequena em relação ao SVM. Ao executar a rede neural alguns warnings apareceram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classficador final:\n",
      "  MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
      "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(3,), learning_rate='constant',\n",
      "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Recupero os melhores parâmetros encontrados previamente pelo Grid Search \n",
    "# com 3-Fold\n",
    "best_param = mlp_grid.best_params_.get('hidden_layer_sizes')\n",
    "# Crio o classficador com os melhores parâmetros\n",
    "final_classifier = MLPClassifier(hidden_layer_sizes=best_param)\n",
    "# Treino com todos os dados\n",
    "final_classifier.fit(X,y)\n",
    "print(\"Classficador final:\\n  %s\" %final_classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
