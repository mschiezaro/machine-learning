{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Leia o arquivo abalone do exercicio 2\n",
    "- Faça o preprocessamento do atributo categorico e do atributo de saida como no exercicio 2\n",
    "- Estandardize todos os atributos numéricos. Voce pode estardartizar todo o arquivo de uma vez. \n",
    "Como discutimos em aula esse não é a coisa 100% certa, mas é um erro menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.67495143 -0.68813926  1.31710822 -1.44900723 -1.43989229 -1.18425209\n",
      "  -1.23034422 -1.17096695 -1.20532696 -1.21305408]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.0498915   0.12201495 -0.10824748\n",
      "  -0.30960118 -0.46361041 -0.35684354 -0.20727719]\n",
      " [-0.67495143 -0.68813926  1.31710822 -0.69955786 -0.4322102  -0.34735962\n",
      "  -0.63792816 -0.64833409 -0.60773918 -0.60240383]\n",
      " [-0.67495143  1.45319423 -0.75923905 -1.61555154 -1.5406605  -1.42336423\n",
      "  -1.27214983 -1.2160215  -1.28743825 -1.32081589]\n",
      " [-0.67495143  1.45319423 -0.75923905 -0.82446609 -1.08720356 -1.06469603\n",
      "  -0.97339267 -0.98399054 -0.94074611 -0.85384805]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.0498915   0.07163085  0.25042072\n",
      "  -0.10465173 -0.5514668  -0.35684354  0.65481729]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.17479973  0.17239906 -0.34735962\n",
      "  -0.12402506 -0.29465583 -0.28385572  0.15192884]\n",
      " [-0.67495143 -0.68813926  1.31710822 -0.40810533 -0.38182609 -0.34735962\n",
      "  -0.65118359 -0.64382864 -0.62142439 -0.53056262]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.21643581  0.32355137  0.25042072\n",
      "   0.13394613 -0.20229399 -0.27017051  0.58297608]\n",
      " [ 1.4815881  -0.68813926 -0.75923905  0.00825543 -0.28105788  0.01130858\n",
      "  -0.45337169 -0.74520139 -0.30210268 -0.20727719]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, binarize\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "def pre_processing_data():\n",
    "    # lê os dados do csv\n",
    "    dataset= pd.read_csv(\n",
    "        '/home/mauricio/projects/MO444/lista 3/abalone.csv').values\n",
    "    # Primeiro transformo a coluna categorica (M,F,I) em numerica (0,1,2) \n",
    "    labelEncoder = LabelEncoder()\n",
    "    # transforma a primeira coluna (M,F,I) em (0,1,2) \n",
    "    dataset[:,0] = labelEncoder.fit_transform(dataset[:,0])\n",
    "    # Agora eu aplico o One Hot Coding na primeira coluna\n",
    "    oneHotEncoder = OneHotEncoder(categorical_features=[0])\n",
    "    dataset = oneHotEncoder.fit_transform(dataset).toarray()\n",
    "    # Separo a ultima coluna para poder binarizar\n",
    "    target = dataset[:,10].reshape(-1,1)\n",
    "    # Para valores > 13 transformo em 1, para valores <=13 transformo em 0\n",
    "    binarize(target,threshold=13, copy=False)\n",
    "    # Para funcionar com o StratifiedKFold\n",
    "    target.shape = (4176,)\n",
    "    #Substituo os valores transformados no dataset original\n",
    "    dataset = np.delete(dataset,-1,1)\n",
    "    # Standarização\n",
    "    standard_scaler = StandardScaler()\n",
    "    dataset = standard_scaler.fit_transform(dataset)\n",
    "    return dataset, target\n",
    "\n",
    "X, y = pre_processing_data()\n",
    "# Imprime somente os 10 primeiros dados\n",
    "print(X[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression\n",
    "- Faça o logistic regression com $C=10^{-1,0,1,2,3}$. O Loop externo deve ser um 5-fold CV estratificado. \n",
    "O loop interno para a escolha do hiperparametro deve ser um 3-fold estratificado.\n",
    "- Você tem que fazer o loop interno explicitamente, usando StratifiedKFold e não funções como GridSearchCV\n",
    "- Qual a acurácia do LR com a melhore escolha de parametros (para cada fold)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop interno 1 - Melhor C encontrado = 10.0\n",
      "Loop interno 2 - Melhor C encontrado = 100.0\n",
      "Loop interno 3 - Melhor C encontrado = 100.0\n",
      "Loop interno 4 - Melhor C encontrado = 10.0\n",
      "Loop interno 5 - Melhor C encontrado = 10.0\n",
      "Logistic Regression - Acurácia Média dos 5-fold = 0.896314010648628\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def execute_logistic_regression(reg, X_training, X_test, \n",
    "                                     Y_training,Y_test):\n",
    "    \n",
    "    # Cria o classificador com C = reg e random_state = 1\n",
    "    classifier = LogisticRegression(C=reg, random_state=1)\n",
    "    # Treina o modelo\n",
    "    classifier.fit(X_training, np.ravel(Y_training))\n",
    "    # Calcula a acurácia do classificador com os dados de testes\n",
    "    score = classifier.score(X_test, np.ravel(Y_test))\n",
    "    return score\n",
    "\n",
    "def internal_loop_logistic_regression(X, y):\n",
    "    # Cross validation com 3-fold\n",
    "    folds = 3\n",
    "    # Crio o StratifiedKFold com valores default para o parâmetro \n",
    "    # suffle=False dessa forma posso rodar 100 vezes o split e ele vai \n",
    "    # gerar os mesmos 3 conjuntos\n",
    "    skf = StratifiedKFold(n_splits=folds)\n",
    "    skf.get_n_splits(X, y)\n",
    "    # Valores de C que serão testados\n",
    "    C = [1e-1, 1e0, 1e1, 1e2, 1e3]\n",
    "    best_c = 0.0\n",
    "    best_acc = 0.0\n",
    "    for c in C:\n",
    "        # Variável para acumular acurácias e calcular a media do \n",
    "        # classficador utilizando um determinado C\n",
    "        acc = 0.0\n",
    "        for train_index, test_index in skf.split(X, y):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            acc += execute_logistic_regression(c, X_train, X_test, \n",
    "                                                  y_train, y_test)\n",
    "        # Calcula a media\n",
    "        acc = acc / folds\n",
    "        # Verifica se a acurácia encontrada e a melhor que as anteriores\n",
    "        if acc > best_acc:\n",
    "            # Se for melhor guarda o hyperparametro C para ser usado no \n",
    "            # loop externo\n",
    "            best_acc = acc\n",
    "            best_c = c\n",
    "    return best_c\n",
    "\n",
    "def external_loop_logistic_regression(X, y):\n",
    "    # Cross validation com 5-fold\n",
    "    folds = 5\n",
    "    # Crio o StratifiedKFold com valores default para o parâmetro \n",
    "    # suffle=False dessa forma posso rodar 100 vezes o split e ele vai \n",
    "    # gerar os mesmos 5 conjuntos\n",
    "    skf = StratifiedKFold(n_splits=folds)\n",
    "    skf.get_n_splits(X, y)\n",
    "    # Variavel para acumular acurácias e calcular a media geral do \n",
    "    # classficador\n",
    "    acc = 0\n",
    "    # Para cada Fold\n",
    "    it = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Para cada conjunto de treino, submeto ao loop interno para fazer \n",
    "        # o 3-Fold e calcular o melhor hiperpârametro C\n",
    "        c = internal_loop_logistic_regression(X_train, y_train)\n",
    "        # Com o melhor valor de C encontrado submeto o classficador e \n",
    "        # verifico a acurácia\n",
    "        cur_acc = execute_logistic_regression(c, X_train, X_test, \n",
    "                                                 y_train, y_test)\n",
    "        print(\"Loop interno {0} - Melhor C encontrado = {1}\".format(it, c))\n",
    "        acc += cur_acc\n",
    "        it += 1\n",
    "    # Calcula a mádia\n",
    "    acc_avg = acc / folds\n",
    "    return acc_avg\n",
    "\n",
    "acc = external_loop_logistic_regression(X, y)\n",
    "print(\"Logistic Regression - Acurácia Média dos 5-fold = {0}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta: De acordo com a documentação, se criarmos o StratifiedKFold com suffle=False \n",
    "(que significa o mesmo que deixar com o valor default) podemos rodar 100 vezes \n",
    "o split gerará conjuntos iguais em todas as execuções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear SVM\n",
    "- Faça o LinearSVM com $C=10^{-1,0,1,2,3}$. O loop externo deve ser um 5-fold estratificado. \n",
    "O loop interno um 3-fold estratificado. Neste caso voce nao precisa fazer o 3 fold explicitamente, \n",
    "voce pode usar o GridSearchCV.\n",
    "- Qual a acurácia do LinearSVM com a melhor escolha de C?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop interno 1 - Melhor C encontrado = 10.0\n",
      "Loop interno 2 - Melhor C encontrado = 10.0\n",
      "Loop interno 3 - Melhor C encontrado = 0.1\n",
      "Loop interno 4 - Melhor C encontrado = 1.0\n",
      "Loop interno 5 - Melhor C encontrado = 10.0\n",
      "SVM - Acurácia Média dos 5-fold = 0.8984688418076242\n"
     ]
    }
   ],
   "source": [
    "def internal_loop_svm(X, y):\n",
    "    # Parâmetros a serem testados, nesse caso somente vamos variar o C\n",
    "    param_grid = [{'C': [1e-1, 1e0, 1e1, 1e2, 1e3]}]\n",
    "    svm = LinearSVC(random_state=1)\n",
    "    # O Grid Search ja eh criado com valores de 3-Kfold e StratifiedKfold\n",
    "    # por default\n",
    "    gridSearch = GridSearchCV(svm, param_grid,cv=3)\n",
    "    gridSearch.fit(X, y)\n",
    "    return gridSearch.best_params_.get('C')\n",
    "\n",
    "\n",
    "def external_loop_svm(X, y):\n",
    "    # Cross validation com 5-fold\n",
    "    folds = 5\n",
    "    # Crio o StratifiedKFold com valores default para o parâmetro \n",
    "    # suffle=False dessa forma posso rodar 100 vezes o split e ele vai \n",
    "    # gerar os mesmos 5 conjuntos    \n",
    "    skf = StratifiedKFold(n_splits=folds)\n",
    "    skf.get_n_splits(X, y)\n",
    "    # Variavel para acumular acurácias e calcular a media geral do \n",
    "    # classficador\n",
    "    acc = 0\n",
    "    it = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # Para cada conjunto de treino, submeto ao loop interno para fazer \n",
    "        # o 3-Fold e calcular o melhor hiperparâmetro C\n",
    "        c = internal_loop_svm(X_train, y_train)\n",
    "        # Com o melhor valor de C encontrado submeto o classficador e \n",
    "        # verifico a acurácia\n",
    "        svm = LinearSVC(C=c)\n",
    "        svm.fit(X_train, y_train)\n",
    "        cur_acc = svm.score(X_test, y_test)\n",
    "        print(\"Loop interno {0} - Melhor C encontrado = {1}\".format(it, c))        \n",
    "        acc += cur_acc\n",
    "        it += 1\n",
    "    # Calcula a média\n",
    "    acc_avg = acc / folds\n",
    "    return acc_avg\n",
    "\n",
    "acc_svm  = external_loop_svm(X, y)\n",
    "print(\"SVM - Acurácia Média dos 5-fold = {0}\".format(acc_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta: De acordo com a documentação, ao criarmos o StratifiedKFold com suffle=False  \n",
    "(que significa o mesmo que deixar com o valor default) se rodarmos 100 vezes o split gerará \n",
    "conjuntos iguais em todas as execuções. No caso do SVM apesar de colocarmos o randomState=1, \n",
    "por causa da implementação do GridSearch, o resultado final\n",
    "apresenta uma pequena variação a cada execução (0.8970, 0.8979, 0.8996), diferentemente dos outros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA\n",
    "- Faça o LDA. Reporte a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA - Acurácia Média dos 5-fold = 0.8960713353507093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mauricio/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "def lda(X, y):\n",
    "    # Cross validation com 5-fold\n",
    "    folds = 5\n",
    "    # Crio o StratifiedKFold com valores default para o parametro \n",
    "    # suffle=False dessa forma posso rodar 100 vezes o split e ele vai \n",
    "    # gerar os mesmos  5 conjuntos    \n",
    "    skf = StratifiedKFold(n_splits=folds)\n",
    "    skf.get_n_splits(X, y)\n",
    "    acc = 0\n",
    "    it = 1\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        lda = LinearDiscriminantAnalysis()\n",
    "        lda.fit(X_train, y_train)\n",
    "        cur_acc = lda.score(X_test, y_test)\n",
    "        acc += cur_acc\n",
    "        it += 1\n",
    "    # Calcula a média\n",
    "    acc_avg = acc / folds\n",
    "    return acc_avg\n",
    "\n",
    "acc_lda = lda(X, y)\n",
    "print(\"LDA - Acurácia Média dos 5-fold = {0}\".format(acc_lda))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resposta:  De acordo com a documentação, ao criarmos o StratifiedKFold com suffle=False \n",
    "(que significa o mesmo que deixar com o valor default) se rodarmos 100 vezes o split gerará \n",
    "conjuntos iguais em todas as execuções. No caso do LDA ainda ao executarmos um warning é gerado\n",
    "alertando que existem variáveis colineares, não é o objetivo do exercício,mas poderíamos \n",
    "analisar se aplicar uma redução de dimensionalidade poderíamos ter resultados ainda melhores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador final\n",
    "- Qual o melhor classificador para esse problema?\n",
    "- Se não o LDA, calcule o hiperparametro C a ser usado\n",
    "- Gere o classificador final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apesar de apresentar alguma variação nos resultados o SVM ainda foi um pouco melhor, apesar que todos os resultados dos classificadores ficarem muito próximos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "[[  5.55385559e-04  -1.29556095e-02   1.20276932e-02  -2.63469188e-01\n",
      "    1.67873266e-01   8.69969904e-02   1.42780971e+00  -1.31588049e+00\n",
      "   -2.67271610e-01   2.57234689e-01]]\n"
     ]
    }
   ],
   "source": [
    "c_final = internal_loop_svm(X, y)\n",
    "svm = LinearSVC(C=c_final)\n",
    "svm.fit(X, y)\n",
    "print(svm)\n",
    "print(svm.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Só como comparação, como faríamos o nested cross validation usando somente funções do sklearn para achar a acurácia média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.89822845995\n"
     ]
    }
   ],
   "source": [
    "# Parâmetros a serem testados, nesse caso somente vamos variar o C\n",
    "param_grid = [{'C': [1e-1, 1e0, 1e1, 1e2, 1e3]}]\n",
    "svm = LinearSVC(random_state=1)\n",
    "# O Grid Search ja eh criado com valores de 3-Kfold e StratifiedKfold\n",
    "# por default\n",
    "gridSearch = GridSearchCV(svm, param_grid,cv=3)\n",
    "gridSearch.fit(X, y)\n",
    "nested_score = cross_val_score(gridSearch, X=X, y=y, cv=5)\n",
    "print(nested_score.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
